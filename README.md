# Równanie płci: Co mówią nam modele językowe?

## Abstrakt
W tym raporcie przyglądamy się, jak sztuczna inteligencja (AI) przetwarza i rozumie język w kontekście płci.
Modele językowe, takie jak te stosowane w wyszukiwarkach czy chatbotach, uczą się na podstawie ogromnych zbiorów
danych z internetu. Problem polega na tym, że w tych danych mogą być ukryte uprzedzenia i stereotypy, które AI może
nieświadomie wzmacniać.

W ramach raportu chcemy budować świadomość i rozpocząć społeczną rozmowę o sztucznej inteligencji w życiu społecznym i biznesowym.

Projekt będzie dostępny za darmo, jaki i dane na podstawie których został napisan, tak żeby każdy mógł zamodzielnie zweryfikować dane i analizy, które przeprowadzimy

# Sponsorzy 

Szukamy sponsora strategicznego dla raportu oraz sponsorów głównych.
Sponsorzy dostaną:
 - miejsce na okładce raportu
 - miejsce w wydzielonym miejscu raportu, gdzie będą mogli opisać swoje firmy.
 - udostępnienie linków do swoich stron firmowych.

 więcej informacji na stronie [Agidot](https://agidot.eu)

# Patronat medialny

Już w krótce więcej informaci :)


## Jak dołączyć do projektu?

Jest kilka sposobów na dołączenie do projektu:
 - zbieranie danych do dokumentów excel w folderze 'zrodla-danych'. 
    - zapisywanie ofert pracy i kategoryzacjia ich - wypełnienie tytułu, url oferty, treści oferty i kategorii
    - zapisywanie par słów w wersji żeńskiej i męskiej
    - zapisywanie słów które mogą mieć znaczenie z perspektywy różnić żeńsko/męskich
 - przygotowanie skryptów python do analizy danych - np. wzorując się na udostępnionych przykładach (np. analiza ilości wystąpień słów)
 - analiza danych - na podstawie zebranych źródeł danych, wygenerowane zostaną (przez skrypty analizujące teksty) dane, które trzeba grupować, kategoryzować i analizować
 - promocja i marketing



---

## Wprowadzenie
Rozwój sztucznej inteligencji i modeli językowych otwiera nowe możliwości, ale niesie też zagrożenia związane z utrwalaniem stereotypów płciowych. Celem raportu jest analiza, w jaki sposób AI reprezentuje płeć oraz jak można przeciwdziałać potencjalnym uprzedzeniom.

## Badanie stanu faktycznego
### Teoretyczne podstawy
- Definicja modeli językowych.
- Pojęcia kluczowe: embeddingi, skojarzenia, uprzedzenia.

### Metodologia
- Analiza embeddingów i skojarzeń płciowych.
- Zbiory danych i sposób ich selekcji.
- Sposoby analizy wyników.

### Jak AI "widzi" płeć?
- Budowa i działanie modeli językowych.
- Analiza płci w treściach generowanych przez AI.
- Ukryte skojarzenia i asymetria w modelach językowych.

## Praktyczne zastosowanie wiedzy
### Analiza językowa ofert pracy
- Zbiór danych: gromadzenie ofert na te same stanowiska.
- Identyfikacja odniesień do płci.
- Analiza statystyczna odniesień kobiecych i męskich.

### Badanie uprzedzeń w języku
- Lista par słów z różnicą płciową (np. "pielęgniarka" vs "pielęgniarz").
- Analiza czasowników i rzeczowników pod kątem asymetrii.
- Porównanie "odległości" semantycznych słów.

### Dodatkowe analizy
1. **Analiza frekwencyjna słów** - sprawdzenie częstotliwości użycia słów stereotypowo kobiecych i męskich.
2. **Analiza sentymentu** - ocena emocjonalnego wydźwięku ofert pracy.
3. **Chmury słów** - wizualizacja dominujących terminów.
4. **Analiza tytułów stanowisk** - identyfikacja różnic w nazewnictwie.
5. **Podział na branże** - sprawdzenie różnic w używanym języku w różnych sektorach.
6. **Ankieta jakościowa** - analiza percepcji języka ofert pracy.



## Referencje
- [AI Acts Gender Gap](https://policyreview.info/articles/news/ai-acts-gender-gap-when-algorithms-get-it-wrong/1743)
- [Amazon AI Recruiting Bias](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/)
