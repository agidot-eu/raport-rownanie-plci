# Równanie płci: Co mówią nam modele językowe?

## Abstrakt

W tym raporcie przyglądamy się, jak sztuczna inteligencja (AI) przetwarza i rozumie język w kontekście płci.  
Modele językowe, takie jak te stosowane w wyszukiwarkach czy chatbotach, uczą się na podstawie ogromnych zbiorów danych z internetu. Problem polega na tym, że w tych danych mogą być ukryte uprzedzenia i stereotypy, które AI może nieświadomie wzmacniać.

Celem raportu jest budowanie świadomości oraz rozpoczęcie społecznej dyskusji na temat roli sztucznej inteligencji w życiu społecznym i biznesowym.

Projekt, wraz z danymi, na podstawie których został napisany, będzie dostępny za darmo. Dzięki temu każdy będzie mógł samodzielnie zweryfikować dane oraz analizy, które przeprowadzimy.

## Sponsorzy 

Szukamy sponsora strategicznego dla raportu oraz sponsorów głównych.  
Sponsorzy otrzymają:

- miejsce na okładce raportu,  
- sekcję w wydzielonej części raportu, gdzie będą mogli opisać swoje firmy,  
- możliwość umieszczenia linków do swoich stron firmowych.

Więcej informacji na stronie [Agidot](https://agidot.eu).

## Patronat medialny

Już wkrótce więcej informacji. :)

## Jak dołączyć do projektu?

Istnieje kilka sposobów na zaangażowanie się w projekt:

- **Zbieranie danych** w arkuszach Excel w folderze `zrodla-danych`:  
  - zapisywanie ofert pracy i ich kategoryzacja (wypełnienie tytułu, URL oferty, treści oferty oraz kategorii),  
  - tworzenie par słów w wersji żeńskiej i męskiej,  
  - identyfikowanie słów, które mogą mieć znaczenie z perspektywy różnic płciowych.

- **Przygotowanie skryptów w Pythonie** do analizy danych, np. wzorując się na udostępnionych przykładach (np. analiza liczby wystąpień określonych słów).

- **Analiza danych** na podstawie zgromadzonych źródeł. Wygenerowane przez skrypty dane należy grupować, kategoryzować i analizować.

- **Promocja i marketing** projektu.

Zapraszamy do współpracy!


---

## Wprowadzenie
Rozwój sztucznej inteligencji i modeli językowych otwiera nowe możliwości, ale niesie też pewne zagrożenia, w tym te związane z utrwalaniem stereotypów płciowych. Celem raportu jest analiza, w jaki sposób AI reprezentuje płeć oraz jak można przeciwdziałać potencjalnym uprzedzeniom.

## Badanie stanu faktycznego
### Teoretyczne podstawy
- Definicja modeli językowych.
- Pojęcia kluczowe: embeddingi, skojarzenia, uprzedzenia.

### Metodologia
- Wykorzstany model językowy
- Analiza embeddingów i skojarzeń płciowych.
- Zbiory danych i sposób ich selekcji.
- Sposoby analizy wyników.

### Jak AI "widzi" płeć?
- Budowa i działanie modeli językowych.
- Analiza płci w treściach generowanych przez AI.
- Ukryte skojarzenia i asymetria w modelach językowych.

## Praktyczne zastosowanie wiedzy
### Analiza językowa ofert pracy
- Zbiór danych: gromadzenie ofert na te same stanowiska.
- Identyfikacja odniesień do płci.
- Analiza statystyczna odniesień kobiecych i męskich.

### Badanie uprzedzeń w języku
- Lista par słów z różnicą płciową (np. "pielęgniarka" vs "pielęgniarz").
- Analiza czasowników i rzeczowników pod kątem asymetrii.
- Porównanie "odległości" semantycznych słów.

### Dodatkowe analizy
1. **Analiza frekwencyjna słów** - sprawdzenie częstotliwości użycia słów stereotypowo kobiecych i męskich.
2. **Analiza sentymentu** - ocena emocjonalnego wydźwięku ofert pracy.
3. **Chmury słów** - wizualizacja dominujących terminów.
4. **Analiza tytułów stanowisk** - identyfikacja różnic w nazewnictwie.
5. **Podział na branże** - sprawdzenie różnic w używanym języku w różnych sektorach.
6. **Ankieta jakościowa** - analiza percepcji języka ofert pracy.



## Referencje
- [AI Acts Gender Gap](https://policyreview.info/articles/news/ai-acts-gender-gap-when-algorithms-get-it-wrong/1743)
- [Amazon AI Recruiting Bias](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/)
